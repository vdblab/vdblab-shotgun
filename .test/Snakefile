import os
import json
import yaml
import shutil

from pathlib import Path


# is a string so we dont have weird issues where ints get cast to floats, adding a ".0"
total_depths = "100000"  # config["total_depths"]
reps = 1  # config["reps"]

output_reads = expand(
    "{rep}_depth{depth}_R{readdir}.fastq.gz",
    rep=reps,
    depth=total_depths,
    readdir=[1, 2],
)
output_stats = expand(
    "{rep}_depth{depth}.statsfastq",
    rep=reps,
    depth=total_depths,
)


localrules:
    all,
    make_input_table,


all_results = [
    output_reads,
    output_stats,
]


rule all:
    input:
        all_results,
        expand("clean_{rep}_depth{depth}.done", rep=reps, depth=total_depths),


rule get_references:
    output:
        mockdir=directory("mock"),
    shell:
        """
    set -eoux pipefail
    # wget complains if this is present
    if [ -f D6331.refseq.zip ]
    then
    echo "refs present"
    else
        wget -N https://s3.amazonaws.com/zymo-files/BioPool/D6331.refseq.zip
        unzip D6331.refseq.zip
    fi
    # snakemake doesn't create outputs labeled as directories
    mkdir -p {output.mockdir}

    # add some of the human genome to our reference pool
    curl -s  "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=nucleotide&id=NC_060945.1&rettype=fasta&retmode=txt"> D6331.refseq/genomes/t2t_chr21.fasta


    # borrowed some logic from https://www.biostars.org/p/294920/ to smoosh together sequences
    # otherwise, art with generate nreads PER Sequence, not per genome
    for fasta in D6331.refseq/genomes/*fasta
    do
      name=$(basename $fasta | sed "s|.fasta||g")
      cat $fasta | grep -v "^>" | awk 'BEGIN {{ ORS=""; print ">${{name}}_concatenated\\n" }} {{ print }}' > {output.mockdir}/${{name}}.fasta
    done

    """


rule make_input_table:
    """ this could be modified to incorporate different depth schemes per bug,
    but for a first pass we do even depths
    """
    input:
        mockdir="mock",
    output:
        outtable="sim_tables/{rep}_depth{depth}.tab",
    run:
        import glob
        import math

        mocks = glob.glob(input.mockdir + "/*.fasta")
        depth = int(wildcards.depth)
        nmocks = len(mocks)
        each_non_spike = math.floor(depth / nmocks)
        with open(output.outtable, "w") as outf:
            for mock in mocks:
                if each_non_spike != 0:
                    outf.write(f"{mock}\t{each_non_spike}\n")


rule simulate:
    input:
        mockdir="mock",
        intable="sim_tables/{rep}_depth{depth}.tab",
    output:
        R1="{rep}_depth{depth}_R1.fastq.gz",
        R2="{rep}_depth{depth}_R2.fastq.gz",
        intermediate_trigger=touch(
            "{rep}_depth{depth}_individual_reference_fastq_present"
        ),
    params:
        tmppre=lambda wildcards: f"tmp_{wildcards.rep}_depth{wildcards.depth}",
    container:
        "docker://ghcr.io/vdblab/art:2016.06.05"
    threads: 4
    shell:
        """
    set -euxo pipefail

    # look a loop! could use parallel but this is a one-off for generating test data.
    cat {input.intable} | while read ref nreads
    do
        refbase=$(basename $ref)
        art_illumina --seqSys HS25 --in $ref  --paired --len 150 --rcount $nreads --mflen 500 --sdev 10 --out {params.tmppre}_${{refbase}}_R --rndSeed {wildcards.rep}
    done

    ls {params.tmppre}*
    cat {params.tmppre}*R1.fq | pigz > {output.R1}
    cat {params.tmppre}*R2.fq | pigz > {output.R2}
    """


rule stats:
    input:
        R1="{rep}_depth{depth}_R1.fastq.gz",
        R2="{rep}_depth{depth}_R2.fastq.gz",
        intermediate_trigger="{rep}_depth{depth}_individual_reference_fastq_present",
    output:
        stats="{rep}_depth{depth}.statsfastq",
    params:
        tmppre=lambda wildcards: f"tmp_{wildcards.rep}_depth{wildcards.depth}",
    container:
        "docker://ghcr.io/vdblab/seqkit:2.3.1"
    threads: 8
    shell:
        """
    # gather all the per-reference fastq stats
    seqkit stats {params.tmppre}*.fq > {output.stats}
    # gather the final stats
    seqkit stats {input.R1} {input.R2} | tail -n+2  >> {output.stats}
    """


rule cleanup:
    input:
        "{rep}_depth{depth}_individual_reference_fastq_present",
        "{rep}_depth{depth}.statsfastq",
    output:
        touch("clean_{rep}_depth{depth}.done"),
    params:
        tmppre=lambda wildcards: f"tmp_{wildcards.rep}_depth{wildcards.depth}",
    shell:
        """
        rm {params.tmppre}*fq
        rm {params.tmppre}*aln
        """
