import os
import json
import yaml
import shutil

from pathlib import Path
from snakemake.utils import validate


include: "rules/common.smk"


configfile: os.path.join(workflow.basedir, "../config/config.yaml")


envvars:
    "TMPDIR",
    "SNAKEMAKE_PROFILE",


validate(
    config,
    str(workflow.main_snakefile).replace(
        "workflow/Snakefile", "config/config.schema.yaml"
    ),
)

SHARDS = make_shard_names(config["nshards"])


onstart:
    with open("config_used.yaml", "w") as outfile:
        yaml.dump(config, outfile)

    if not os.path.exists("logs"):
        os.makedirs("logs")


localrules:
    all,


"""
we have to fix some inputs to downstream applications if we are running all together:
we do this for the assembly because that config entry is referenced many times in the binning and annotation workflows
for entries like R1/R2, its eaiest to set those in the conditional block below, as those are only used by a single rule within a given workflow
"""

if config["stage"] == "all":
    config["assembly"] = f"megahit_{config['sample']}.assembly.fasta"


"""
similarly, we have to mock the downsample parameters if we aren't running with stage=downsample
"""
if config["stage"] != "downsample":
    config["depths"] = [0]
    config["reps"] = [0]


#
# Preprocess Module
#
module preprocess:
    snakefile:
        "rules/preprocess.smk"
    config:
        config


use rule * from preprocess as preprocess_*


#
# Biobakery Module
#
module biobakery:
    snakefile:
        "rules/biobakery.smk"
    config:
        config
    skip_validation:
        True


use rule * from biobakery as biobakery_*


#
# Kraken Module
#
module kraken:
    snakefile:
        "rules/kraken.smk"
    config:
        config
    skip_validation:
        True


use rule * from kraken as kraken_*


#
# Assembly Module
#
module assembly:
    snakefile:
        "rules/assembly.smk"
    config:
        config
    skip_validation:
        True


use rule * from assembly as assembly_*


#
# Utils Module
#
module utils:
    snakefile:
        "rules/utils.smk"
    config:
        config


#
# RGI Module
#
module rgi:
    snakefile:
        "rules/RGI.smk"
    config:
        config


use rule * from rgi as rgi_*


#
# Binning Module
#
module binning:
    snakefile:
        "rules/binning.smk"
    config:
        config


use rule * from binning as binning_*


#
# annotation Module
#
if config["stage"] in ["annotate", "all"]:

    module annotate:
        snakefile:
            "rules/annotate.smk"
        config:
            config
        skip_validation:
            True

    use rule * from annotate as annotate_*


#
# downsample Module
#
module downsample:
    snakefile:
        "rules/downsample.smk"
    config:
        config
    skip_validation:
        True


use rule * from downsample as downsample_*


#
# hla Module
#
module hla:
    snakefile:
        "rules/HLA.smk"
    config:
        config
    skip_validation:
        True


use rule * from hla as hla_*


if config["stage"] == "classify_bins":

    #
    # hla Module
    #
    module classify_bins:
        snakefile:
            "rules/classify_bins.smk"
        config:
            config
        skip_validation:
            True

    use rule * from classify_bins as classify_bins_*


"""
Notes:
put all the logic here to connect pipeline stages (eg setting biobakery to using preprocessed results rather than config's R1 and R2
because the concat rule exists in both the preprocessing and kraken
snakefiles, we override the ins and outs of one of them.  Since the new
outputs aren't in rule all, this clips the rule from the dag

The wildcard_constraints below ensures that the sample wildcard never ends with _shard001
needing this probably means I could specify file names more cleanly :/
"""

if config["stage"] == "all":

    use rule cat_pair from biobakery as biobakery_cat_pair with:
        input:
            R1="hostdepleted/{sample}_R1.fastq.gz",
            R2="hostdepleted/{sample}_R2.fastq.gz",

    use rule RGI from rgi as rgi_RGI with:
        input:
            R1="hostdepleted/{sample}_R1.fastq.gz",
            R2="hostdepleted/{sample}_R2.fastq.gz",
            db=config["CARD_db_json"],

    use rule OptiType_subset_fastq from hla as hla_OptiType_subset_fastq with:
        input:
            R1="host/{sample}_all_host_reads_R1.fastq.gz",
            R2="host/{sample}_all_host_reads_R2.fastq.gz",
            alleles=config["optityper_hla_dna"],

    use rule megahit from assembly as assembly_megahit with:
        input:
            R1=["hostdepleted/{sample}_R1.fastq.gz"],
            R2=["hostdepleted/{sample}_R2.fastq.gz"],

    use rule concat_R1_R2 from kraken as kraken_concat_R1_R2 with:
        input:
            R1=touch("input_F"),
            R2=touch("input_R"),
        output:
            R1=temp(touch("output_F")),
            R2=temp(touch("output_R")),

    use rule kraken_standard_run from kraken as kraken_kraken_standard_run with:
        input:
            R1="trimmed/{sample}_shard{shard}_trim_R1.fastq.gz",
            R2="trimmed/{sample}_shard{shard}_trim_R2.fastq.gz",
            db=config["kraken2_db"],
        output:
            out="kraken2/{sample}_shard{shard}_kraken2.out",
            unclass_R1="kraken2/{sample}_shard{shard}_kraken2_unclassified_1.fastq",
            unclass_R2="kraken2/{sample}_shard{shard}_kraken2_unclassified_2.fastq",
            report=temp("kraken2/{sample}_shard{shard}_kraken2.report"),
        log:
            e="logs/kraken_{sample}_shard{shard}.e",

    use rule compress_kraken_unclassified from kraken as kraken_compress_kraken_unclassified with:
        input:
            R1=[
                f"kraken2/{{sample}}_shard{shard}_kraken2_unclassified_1.fastq"
                for shard in SHARDS
            ],
            R2=[
                f"kraken2/{{sample}}_shard{shard}_kraken2_unclassified_2.fastq"
                for shard in SHARDS
            ],

    use rule kraken_merge_shards from kraken as kraken_kraken_merge_shards with:
        input:
            #reports = rules.kraken_kraken_standard_run.output.report,
            reports=[
                f"kraken2/{{sample}}_shard{shard}_kraken2.report" for shard in SHARDS
            ],
        output:
            out="kraken2/{sample}_kraken2.report",
        wildcard_constraints:
            sample=".+(?<!shard\d\d\d)",


# in "all" mode, we do NOT HLA type as we regularly lack sufficient host depth
if config["stage"] == "all":
    outputs = [
        rules.preprocess_all.input,
        rules.biobakery_all.input,
        rules.assembly_all.input,
        rules.kraken_all.input,
        rules.rgi_all.input,
        rules.binning_all.input,
        rules.annotate_all.input,
        # rules.hla_all.input,
    ]
else:
    outputs = getattr(rules, f"{config['stage']}_all").input


rule all:
    input:
        outputs,
    default_target: True
