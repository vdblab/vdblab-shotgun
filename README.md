# VDB Shotgun Pipeline

## Prerequisites

- [Snakemake](https://snakemake.readthedocs.io/en/stable/) We currently recommend installing version 7.31.1 as later versions may be inconsistent with this pipeline.
- [Apptainer/Singularity](https://apptainer.org/): while in many cases we do provide conda envs the only method of execution we support is via containers.
- (optional) [A Snakemake Profile](https://snakemake.readthedocs.io/en/stable/executing/cli.html#profiles): this coordinates the execution of jobs on whatever hardware you are using.

## Recommendations

- set up a fresh conda virtual environment, install snakemake version 7.31.1 and python 3.10.9 and use this environment to run all analyses.
- configure your .bashrc file to configure the `$SNAKEMAKE_PROFILE` variable to use the vdblab-profile (A private repo for vdblab members) or to point to whatever snakmake profile you will be using. At the same time add an `$TMPDIR` environmental variable definition to your .bashrc file to define where you would like to put temporary files.  If doing this on lilac - recommended that you point this to a location in your /data/ directory.


## **Important Notes**:

- Set the location of your profile to the environment variable `$SNAKEMAKE_PROFILE` (eg `export SNAKEMAKE_PROFILE=/path/to/your/profile/`)  (Recommended that you add this to the .bashrc file in your home directory to have this environmental variable instated upon startup.)
- For the purposes of the examples, we added the `--dry-run` flag for the user to preview the rules to be executed.  Remove this step to execute the commands.
- All database paths are configured in `config/config.yaml`  Change the paths to reflect where the databases can be found on your machine.  For a uniform way to fetch and build all the databases, see https://github.com/vdblab/resources
- If running analysis on SRA files, when specifying the config of your command set the dedup-platform=SRA switch.  If this tag is not successfully set the pipeline will hang indefinitely at the dedup stage.

## Simulating test data:
```
snakemake --snakefile .test/Snakefile --directory .test/simulated/
```
## Main Pipeline
### Usage
```sh
snakemake \
  --directory tmpout/ \
  --config \
    sample=473 \
    R1=[/data/brinkvd/data/shotgun/test/473/473_IGO_12587_1_S132_L003_R1_001.fastq.gz] \
    R2=[/data/brinkvd/data/shotgun/test/473/473_IGO_12587_1_S132_L003_R2_001.fastq.gz] \
    nshards=4 \
    stage=all \
  --dry-run
```

### Outputs

* MultiQC-ready reports
* Microbe relative abundances (MetaPhlAn3, Kraken2)
* Metabolic pathway relative abundances (HUMAnN3)
* Metagenome assembled genomes (MetaSPAdes)
* AMR profiles with Abricate and RGI
* MAGs with MetaWRAP (Metabat2, CONCOCT, Maxbin2)
* Gene prediction and annotation (MetaErg)
* Secondary metabolite gene clusters (antiSMASH)
* Antimicrobial resistance and virulence genes (ABRicate, AMRFinderPlus)
* Carbohydrate active enzyme (CAZyme) annotation (dbCAN3)

### Workflow

The rule DAG for a single sample looks like this:

<img src="https://github.com/vdblab/vdblab-shotgun/raw/main/images/all_dag.png" alt="Main Shotgun Pipeline DAG" height="600">


Different modules of the workflow can be run indenpendently using the `stage` config entry.



### MultiQC
Just run [MultiQC](http://dx.doi.org/10.1093/bioinformatics/btw354) on a directory, no need to use Snakemake
```sh

cp -r tmppre/reports tmpreports
cp tmpassembly/quast/quast_473/report.tsv ./tmpreports/
ver="v1.12"
docker run -V $PWD:$PWD docker://ewels/multiqc:${ver} multiqc \
    --config vdb_shotgun/multiqc_config.yaml --force \
    --title "a multiqc report for some test data" \
    -b "generated by ${ver}" --filename multiqc_report.html \
    reports/ --interactive
```

## Preprocessing
<img src="https://github.com/vdblab/vdblab-shotgun/raw/main/images/preprocess_dag.png" alt="Shotgun Preprocessing Pipeline DAG" height="600">

```sh
snakemake \
  --directory tmppreprocess/ \
  --config \
    sample=473 \
    R1=[/data/brinkvd/data/shotgun/test/473/473_IGO_12587_1_S132_L003_R1_001.fastq.gz] \
    R2=[/data/brinkvd/data/shotgun/test/473/473_IGO_12587_1_S132_L003_R2_001.fastq.gz] \
    nshards=4 \
    dedup_platform=NovaSeq \
    stage=preprocess \
  --dry-run
```
#### Tools used
* BBTools ([site](https://jgi.doe.gov/data-and-tools/software-tools/bbtools/) | [paper](https://doi.org/10.1371/journal.pone.0185056))
* SeqKit ([site](https://bioinf.shenwei.me/seqkit/) | [paper](https://doi.org/10.1371/journal.pone.0163962))
* Bowtie2 ([site](https://bowtie-bio.sourceforge.net/bowtie2/index.shtml) | [paper](https://doi.org/10.1093/bioinformatics/bty648))
* Snap ([site](https://www.microsoft.com/en-us/research/project/snap/) | [paper](https://doi.org/10.1101/2021.11.23.469039
History))
* SortMeRNA ([site](https://bioinfo.lifl.fr/RNA/sortmerna/) | [paper](https://doi.org/10.1093/bioinformatics/bts611))
* FastQC ([site](https://www.bioinformatics.babraham.ac.uk/projects/fastqc/))
* 2-step host removal [descibed here](https://doi.org/10.1101/2021.11.23.469039), extended to use both human and mouse genomes

## Biobakery

<img src="https://github.com/vdblab/vdblab-shotgun/raw/main/images/biobakery_dag.png" alt="Shotgun Biobakery Profiling Pipeline DAG" height="600">


```sh
snakemake \
  --directory tmpbiobakery/ \
  --config \
    sample=473 \
    R1=[/data/brinkvd/data/shotgun/test/473/473_IGO_12587_1_S132_L003_R1_001.fastq.gz] \
    R2=[/data/brinkvd/data/shotgun/test/473/473_IGO_12587_1_S132_L003_R2_001.fastq.gz] \
    stage=biobakery \
  --dry-run
```

#### Tools used
* MetaPhlAn3 ([site](http://huttenhower.sph.harvard.edu/metaphlan) | [paper](https://doi.org/10.7554/eLife.65088))
* HUMAnN3 ([site](https://huttenhower.sph.harvard.edu/humann) | [paper](https://doi.org/10.7554/eLife.65088))


## Kraken2/Bracken

<img src="https://github.com/vdblab/vdblab-shotgun/raw/main/images/kraken_dag.png" alt="Shotgun Kraken/Bracken Pipeline DAG" height="600">

```sh
snakemake \
  --directory tmpkraken/ \
  --config \
    sample=473 \
    R1=[/data/brinkvd/data/shotgun/test/473/473_IGO_12587_1_S132_L003_R1_001.fastq.gz] \
    R2=[/data/brinkvd/data/shotgun/test/473/473_IGO_12587_1_S132_L003_R2_001.fastq.gz] \
    dedup_platform=NovaSeq \
    stage=kraken \
  --dry-run
```

#### Tools used
* Kraken2 ([site](https://ccb.jhu.edu/software/kraken2/) | [paper](https://doi.org/10.1186/s13059-019-1891-0))

## Assembly

<img src="https://github.com/vdblab/vdblab-shotgun/raw/main/images/assembly_dag.png" alt="Shotgun Assembly Pipeline DAG" height="600">

```sh
snakemake \
  --directory tmpassembly/ \
  --config \
    sample=473 \
    R1=[/data/brinkvd/data/shotgun/test/473/473_IGO_12587_1_S132_L003_R1_001.fastq.gz] \
    R2=[/data/brinkvd/data/shotgun/test/473/473_IGO_12587_1_S132_L003_R2_001.fastq.gz] \
    stage=assembly \
  --dry-run
```

#### Tools used
* MetaSPAdes ([site](http://cab.spbu.ru/software/spades/) | [paper](https://doi.org/10.1101/gr.213959.116))
* MetaQUAST ([site](http://quast.sourceforge.net/metaquast) | [paper](https://doi.org/10.1093/bioinformatics/btv697))

## Annotation

<img src="https://github.com/vdblab/vdblab-shotgun/raw/main/images/annotate_dag.png" alt="Shotgun Assembly Annotation DAG" height="600">

```sh
snakemake \
  --directory tmpannotate/ \
  --config \
    sample=473 \
    R1=[/data/brinkvd/data/shotgun/test/473/473_IGO_12587_1_S132_L003_R1_001.fastq.gz] \
    R2=[/data/brinkvd/data/shotgun/test/473/473_IGO_12587_1_S132_L003_R2_001.fastq.gz] \
    assembly=tmpassembly/473.contigs.fasta \
    stage=annotate \
  --dry-run
```

#### Tools used
* MetaErg ([site](https://github.com/xiaoli-dong/metaerg) | [paper](https://doi.org/10.3389/fgene.2019.00999))
* antiSMASH ([site](https://antismash.secondarymetabolites.org/#!/about) | [paper](https://doi.org/10.1093/nar/gkab335))
* ABRicate ([site](https://github.com/tseemann/abricate))
* AMRFinderPlus ([site](https://github.com/ncbi/amr) | [paper](https://doi.org/10.1038/s41598-021-91456-0))
* dbCAN ([site](https://github.com/linnabrown/run_dbcan) | [paper](https://doi.org/10.1093/nar/gky418))

## Binning

<img src="https://github.com/vdblab/vdblab-shotgun/raw/main/images/binning_dag.png" alt="Shotgun Assembly Binning Pipeline DAG" height="600">

```sh
snakemake \
  --directory tmpbinning/ \
  --config \
    sample=473 \
    R1=[/data/brinkvd/data/shotgun/test/473/473_IGO_12587_1_S132_L003_R1_001.fastq.gz] \
    R2=[/data/brinkvd/data/shotgun/test/473/473_IGO_12587_1_S132_L003_R2_001.fastq.gz] \
    assembly=tmpassembly/473.contigs.fasta \
    stage=binning \
  --dry-run
```

## RGI

<img src="https://github.com/vdblab/vdblab-shotgun/raw/main/images/rgi_dag.png" alt="Shotgun RGI Pipeline DAG" height="600">

```sh
snakemake \
  --directory tmprgi/ \
  --config \
    sample=473 \
    R1=[/data/brinkvd/data/shotgun/test/473/473_IGO_12587_1_S132_L003_R1_001.fastq.gz] \
    R2=[/data/brinkvd/data/shotgun/test/473/473_IGO_12587_1_S132_L003_R2_001.fastq.gz] \
    stage=rgi \
  --dry-run
```

#### Tools used
* RGI ([site](https://github.com/arpcard/rgi) | [paper](https://doi.org/10.1093/nar/gkz935))








# Strainphlan Pipeline
This pipeline  StrainPhlAn for each specified species. Strainphlan requires two inputs: sample-level marker pickle files, and strain-level markers extracted from the main database.  These are stored in central subdirectory in the Metaphlan database directory to aid re-running.  If you provide the .sam.bz2 file for a samples that has already been processed into a pkl file, it will use the pregenerated result.

This workflow accepts as input a list of sample's metaphlan `sam.bz2` alignment files, and a list of species of interest. A config argument `strainphlan_markers_dir` serves as a central place for storing both the species- and the sample-level marker files; these are specific to a version of the MetaPHlan database, so we recommend placing that within the metaphlan database directory.

### Usage

```sh
snakemake \
  --snakefile workflow/strainphlan.smk \
  --directory tmpstrain/ \
  --config \
    sams=[path/to/sample1.sam.bz2,path/to/sample2.sam.bz2] \
    strainphlan_markers_dir=/data/brinkvd/resources/dbs/metaphlan/mpa_vJan21_CHOCOPhlAnSGB_202103/marker_outputs/ \
    metaphlan_db=/data/brinkvd/resources/dbs/metaphlan/mpa_vJan21_CHOCOPhlAnSGB_202103/ \
    marker_in_n_samples=2 \
  --dry-run
```

### Outputs
For each input species:

* Multiple sequence alignment of strains detected in samples
* Phylogenetic tree of strains detected in samples

### Workflow

The rule DAG for two example input species looks like this:

<img src="https://github.com/vdblab/vdblab-shotgun/raw/main/workflow/images/strainphlan_dag.png" alt="StrainPhlAn Shotgun Pipeline DAG" width="500">


# Testing and Development
Please see [`development.md`](development.md).
